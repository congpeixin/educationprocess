#configuration for kafka server
kafka.zookeeper.server = 192.168.31.6:2181

#configuration for lda predict 
kafka.ldapredict.topic = ldatopic03
#configuration for article crawler topic
kafka.article.topic = articletopiconline
kafka.article.consumer.root = /articletopic8

kafka.article.spout.maxoffsetbehind = 9223372036854775807
kafka.article.spout.usestartOffsettimeifoffsetoutofrange = true
kafka.article.spout.forcefromstart = true
#startOffsetTime
#LatestTime: -1
#EarliestTime: -2
kafka.article.spout.startoffsettime = -2

#configuration for image download queue/topic writer
kafka.article.imagedownloadqueue.topic = imagedownloadrequest02

#configuration for imagealbummeta  topic
kafka.imagealbummeta.topic = metatopic09
kafka.imagealbummeta.consumer.root = /metatopic09

kafka.imagealbummeta.spout.maxoffsetbehind = 9223372036854775807
kafka.imagealbummeta.spout.usestartOffsettimeifoffsetoutofrange = true
kafka.imagealbummeta.spout.forcefromstart = false
#startOffsetTime
#LatestTime: -1
#EarliestTime: -2
kafka.imagealbummeta.spout.startoffsettime = -2


#configureation for imagerequest kafka producer
metadata.broker.list = 192.168.31.6:9092
request.required.acks = 1

#configuration for hbase(extracted article)
hbase.extracted.zookeeper.quorum = bigdataslave1.dev.dp,bigdataslave2.dev.dp,bigdataslave3.dev.dp
hbase.extracted.zookeeper.port = 2181
hbase.extracted.zookeeper.isdistributed = true
hbase.extracted.namespace = dpa
hbase.extracted.article.tablename = articles03
hbase.extracted.article.table.columnfamily = d

#configuration for hbae(raw article web)
hbase.raw.zookeeper.quorum = bigdataslave1.dev.dp,bigdataslave2.dev.dp,bigdataslave3.dev.dp
hbase.raw.zookeeper.port = 2181
hbase.raw.zookeeper.isdistributed = true
hbase.raw.namespace = dpa
hbase.raw.article.tablename = rawarticles03
hbase.raw.article.table.columnfamily = d

#elasticsearch article index
es.cluster.name = dev.es.dp
es.cluster.ip = 192.168.31.8
es.cluster.port = 9300
es.index.name = articleset03
es.index.type = article
es.index.mapping.file = articlesetmapping.json

#similar article config
#1, use es more like this
#2, use simhash server
similar.algorithm = 2
# es more like this score threshold
similar.es.score = 1.9
# es similar compare fieldname
similar.es.field = content
# simhash server 
simhash.server.url=http://192.168.31.6:8080/simhashServer/v1/duplicateJudge/simhash